%\chapter{README}

\chapter{Goals}\label{chp:goals}

\todo[inline]{Remove implementation details, focus on LRF - optional support from rgbd}

The goal of this project is to implement and evaluate a tracking approach using a Laser range finder which is supported with additional tracking with a RBG-D camera. The object to be tracked is a person, who at start of the experiment is standing in front of the sensors. The sensors are mounted on a Tiago Robot. To enable the tracking, the person will be positioned in a 2D coordinate system measured relative to the position of the robot. This is tracked using the 2D LRF data, supported by the tracking from the 2D image data. Multiple scenarios will be devised where the position of the object to be track changes, the object either is occluded from the field of view of the sensors, or it exits and re-enters the frame.  
The data provided to evaluate the tracking efficiency will be provided through a simulation initially. Following which the experimental set-ups will be recreated in a lab environment. The Tiago robot will be used as the sensor platform to record cases similar to the ones deployed in the simulation. 

Assuming the above-mentioned method is successful in tracking, another approach can be devised. This will involve tracking, using LRF data to be supported by point cloud data from the Kinect (RGBD) sensor. The LRF data will be used to reinforce the tracking of the object in a 3D coordinate frame.
 
Finally, the aim of the project is to compare and illustrate the results of the different methods implemented in it to the previous methods in use by the research group at Uni Bielefeld. \cite{dondrup2015tracking}\cite{4695975}
 
